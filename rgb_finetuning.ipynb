{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectree2.preprocessing.tiling import tile_data, to_traintest_folders\n",
    "from detectree2.models.train import register_train_data, MyTrainer, setup_cfg\n",
    "import rasterio\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='/mnt/e_drive/detectree2/griffith_site/tiles_40_30_0.0'\n",
    "data_folder = out_dir # data_folder is the folder where the .png, .tif, .geojson tiles have been stored\n",
    "to_traintest_folders(data_folder, out_dir, test_frac=0.15, strict=False, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = \"/mnt/e_drive/detectree2/griffith_site/tiles_40_30_0.0/train\"\n",
    "register_train_data(train_location, 'griffith', val_fold=5)\n",
    "\n",
    "# train_location = \"/content/drive/Shareddrives/detectree2/data/Paracou/tiles_\" + appends + \"/train/\"\n",
    "# register_train_data(train_location, \"Paracou\", val_fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base (pre-trained) model from the detectron2 model_zoo\n",
    "base_model = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "\n",
    "# Set the updated model weights from the detectree2 pre-trained model\n",
    "trained_model = \"/mnt/e_drive/detectree2/griffith_site/models/230103_randresize_full.pth\"\n",
    "\n",
    "trains = (\"griffith_train\", ) # Registered train data\n",
    "tests = (\"griffith_val\", ) # Registered validation data\n",
    "\n",
    "out_dir = \"/mnt/e_drive/detectree2/griffith_site/train_outputs_allsites_r2\"\n",
    "\n",
    "cfg = setup_cfg(base_model, trains, tests, trained_model, ims_per_batch=6, warm_iter=0, base_lr=0.00003389, gamma=1.0, workers = 4, eval_period=100, max_iter=6000, out_dir=out_dir) # update_model arg used to load in trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.engine.defaults:Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:detectron2.data.dataset_mapper:[DatasetMapper] Augmentations used in training: [RandomRotation(angle=[0, 360], expand=False), RandomFlip(prob=0.5), RandomBrightness(intensity_min=0.7, intensity_max=1.5), RandomLighting(scale=0.7), RandomContrast(intensity_min=0.6, intensity_max=1.3), RandomSaturation(intensity_min=0.8, intensity_max=1.4), ResizeShortestEdge(short_edge_length=[1000, 1000], max_size=1333)]\n",
      "INFO:detectree2.models.train:[FlexibleDatasetMapper] Augmentations used in training: [RandomRotation(angle=[0, 360], expand=False), RandomFlip(prob=0.5), RandomBrightness(intensity_min=0.7, intensity_max=1.5), RandomLighting(scale=0.7), RandomContrast(intensity_min=0.6, intensity_max=1.3), RandomSaturation(intensity_min=0.8, intensity_max=1.4), ResizeShortestEdge(short_edge_length=[1000, 1000], max_size=1333)]\n",
      "INFO:detectron2.data.build:Removed 0 images with no usable annotations. 44665 images left.\n",
      "INFO:detectron2.data.build:Distribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    tree    | 2047463      |\n",
      "|            |              |\u001b[0m\n",
      "INFO:detectron2.data.build:Using training sampler TrainingSampler\n",
      "INFO:detectron2.data.common:Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "INFO:detectron2.data.common:Serializing 44665 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 2755.87 MiB\n",
      "INFO:detectron2.data.build:Making batched data loader with batch_size=6\n",
      "WARNING:detectron2.solver.build:SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "INFO:detectron2.data.dataset_mapper:[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[1000, 1000], max_size=1333)]\n",
      "INFO:detectree2.models.train:[FlexibleDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[1000, 1000], max_size=1333)]\n",
      "INFO:detectron2.data.build:Distribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    tree    | 512282       |\n",
      "|            |              |\u001b[0m\n",
      "INFO:detectron2.data.common:Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "INFO:detectron2.data.common:Serializing 11167 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 685.03 MiB\n",
      "INFO:detectron2.checkpoint.detection_checkpoint:[DetectionCheckpointer] Loading from /mnt/e_drive/detectree2/griffith_site/models/230103_randresize_full.pth ...\n",
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from /mnt/e_drive/detectree2/griffith_site/models/230103_randresize_full.pth ...\n",
      "/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "INFO:detectree2.models.train:Starting training from iteration 0\n",
      "/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647406761/work/aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "INFO:detectron2.utils.events: eta: 3:34:43  iter: 19  total_loss: 3.277  loss_cls: 0.3466  loss_box_reg: 0.193  loss_mask: 0.5725  loss_rpn_cls: 1.083  loss_rpn_loc: 0.8868    time: 2.1617  last_time: 2.2251  data_time: 0.0504  last_data_time: 0.0314   lr: 3.389e-05  max_mem: 8876M\n",
      "INFO:detectron2.utils.events: eta: 3:30:47  iter: 39  total_loss: 2.196  loss_cls: 0.2809  loss_box_reg: 0.1232  loss_mask: 0.536  loss_rpn_cls: 0.4794  loss_rpn_loc: 0.7575    time: 2.1407  last_time: 2.1594  data_time: 0.0238  last_data_time: 0.0198   lr: 3.389e-05  max_mem: 8876M\n",
      "INFO:detectron2.utils.events: eta: 3:29:57  iter: 59  total_loss: 2.141  loss_cls: 0.26  loss_box_reg: 0.09361  loss_mask: 0.5148  loss_rpn_cls: 0.4634  loss_rpn_loc: 0.747    time: 2.1341  last_time: 2.0127  data_time: 0.0228  last_data_time: 0.0237   lr: 3.389e-05  max_mem: 8876M\n",
      "INFO:detectron2.utils.events: eta: 3:27:53  iter: 79  total_loss: 1.913  loss_cls: 0.2215  loss_box_reg: 0.08076  loss_mask: 0.5144  loss_rpn_cls: 0.3878  loss_rpn_loc: 0.7366    time: 2.1188  last_time: 2.0462  data_time: 0.0204  last_data_time: 0.0124   lr: 3.389e-05  max_mem: 8876M\n",
      "INFO:detectron2.data.dataset_mapper:[DatasetMapper] Augmentations used in inference: []\n",
      "INFO:detectree2.models.train:[FlexibleDatasetMapper] Augmentations used in inference: []\n",
      "INFO:detectron2.data.common:Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "INFO:detectron2.data.common:Serializing 11167 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 685.03 MiB\n",
      "WARNING:detectron2.evaluation.coco_evaluation:COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "INFO:detectron2.evaluation.coco_evaluation:Trying to convert 'griffith_val' to COCO format ...\n",
      "WARNING:detectron2.data.datasets.coco:Using previously cached COCO format annotations at 'eval/griffith_val_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "INFO:detectron2.evaluation.evaluator:Start inference on 11167 batches\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 11/11167. Dataloading: 0.0005 s/iter. Inference: 0.0531 s/iter. Eval: 0.0213 s/iter. Total: 0.0750 s/iter. ETA=0:13:56\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 82/11167. Dataloading: 0.0007 s/iter. Inference: 0.0530 s/iter. Eval: 0.0173 s/iter. Total: 0.0712 s/iter. ETA=0:13:08\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 153/11167. Dataloading: 0.0007 s/iter. Inference: 0.0532 s/iter. Eval: 0.0171 s/iter. Total: 0.0711 s/iter. ETA=0:13:03\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 224/11167. Dataloading: 0.0007 s/iter. Inference: 0.0532 s/iter. Eval: 0.0170 s/iter. Total: 0.0710 s/iter. ETA=0:12:56\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 295/11167. Dataloading: 0.0007 s/iter. Inference: 0.0532 s/iter. Eval: 0.0170 s/iter. Total: 0.0709 s/iter. ETA=0:12:50\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 366/11167. Dataloading: 0.0007 s/iter. Inference: 0.0532 s/iter. Eval: 0.0170 s/iter. Total: 0.0710 s/iter. ETA=0:12:46\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 437/11167. Dataloading: 0.0007 s/iter. Inference: 0.0533 s/iter. Eval: 0.0170 s/iter. Total: 0.0710 s/iter. ETA=0:12:42\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 508/11167. Dataloading: 0.0007 s/iter. Inference: 0.0533 s/iter. Eval: 0.0170 s/iter. Total: 0.0711 s/iter. ETA=0:12:37\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 578/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0170 s/iter. Total: 0.0711 s/iter. ETA=0:12:33\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 649/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0170 s/iter. Total: 0.0711 s/iter. ETA=0:12:28\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 719/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0170 s/iter. Total: 0.0712 s/iter. ETA=0:12:23\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 790/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0170 s/iter. Total: 0.0711 s/iter. ETA=0:12:18\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 861/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0170 s/iter. Total: 0.0711 s/iter. ETA=0:12:13\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 932/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0170 s/iter. Total: 0.0711 s/iter. ETA=0:12:07\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1003/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:12:02\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1074/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:57\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1145/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:52\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1216/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:47\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1287/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:42\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1358/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:37\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1428/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:32\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1499/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0169 s/iter. Total: 0.0711 s/iter. ETA=0:11:27\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1547/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0180 s/iter. Total: 0.0722 s/iter. ETA=0:11:34\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1618/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0179 s/iter. Total: 0.0721 s/iter. ETA=0:11:28\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1689/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0179 s/iter. Total: 0.0721 s/iter. ETA=0:11:23\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1760/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0178 s/iter. Total: 0.0720 s/iter. ETA=0:11:17\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1831/11167. Dataloading: 0.0007 s/iter. Inference: 0.0534 s/iter. Eval: 0.0178 s/iter. Total: 0.0720 s/iter. ETA=0:11:12\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1902/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0178 s/iter. Total: 0.0720 s/iter. ETA=0:11:06\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 1973/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0177 s/iter. Total: 0.0719 s/iter. ETA=0:11:01\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2044/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0177 s/iter. Total: 0.0719 s/iter. ETA=0:10:56\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2115/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0177 s/iter. Total: 0.0719 s/iter. ETA=0:10:50\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2186/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0176 s/iter. Total: 0.0719 s/iter. ETA=0:10:45\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2257/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0176 s/iter. Total: 0.0719 s/iter. ETA=0:10:40\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2328/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0176 s/iter. Total: 0.0718 s/iter. ETA=0:10:34\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2398/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0176 s/iter. Total: 0.0718 s/iter. ETA=0:10:29\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2469/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0175 s/iter. Total: 0.0718 s/iter. ETA=0:10:24\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2540/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0175 s/iter. Total: 0.0718 s/iter. ETA=0:10:19\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2610/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0175 s/iter. Total: 0.0718 s/iter. ETA=0:10:14\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2680/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0175 s/iter. Total: 0.0718 s/iter. ETA=0:10:09\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2751/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0175 s/iter. Total: 0.0718 s/iter. ETA=0:10:04\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2821/11167. Dataloading: 0.0007 s/iter. Inference: 0.0535 s/iter. Eval: 0.0175 s/iter. Total: 0.0718 s/iter. ETA=0:09:58\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2891/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0718 s/iter. ETA=0:09:53\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 2962/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0717 s/iter. ETA=0:09:48\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3032/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0717 s/iter. ETA=0:09:43\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3103/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0717 s/iter. ETA=0:09:38\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3173/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0717 s/iter. ETA=0:09:33\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3243/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0717 s/iter. ETA=0:09:28\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3313/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0174 s/iter. Total: 0.0717 s/iter. ETA=0:09:23\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3384/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0173 s/iter. Total: 0.0717 s/iter. ETA=0:09:18\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3433/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0178 s/iter. Total: 0.0722 s/iter. ETA=0:09:18\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3503/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0178 s/iter. Total: 0.0721 s/iter. ETA=0:09:12\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3574/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0178 s/iter. Total: 0.0721 s/iter. ETA=0:09:07\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3645/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0177 s/iter. Total: 0.0721 s/iter. ETA=0:09:02\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3716/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0177 s/iter. Total: 0.0721 s/iter. ETA=0:08:57\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3787/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0177 s/iter. Total: 0.0721 s/iter. ETA=0:08:51\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3857/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0177 s/iter. Total: 0.0721 s/iter. ETA=0:08:46\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3927/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0177 s/iter. Total: 0.0721 s/iter. ETA=0:08:41\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 3997/11167. Dataloading: 0.0007 s/iter. Inference: 0.0536 s/iter. Eval: 0.0177 s/iter. Total: 0.0721 s/iter. ETA=0:08:36\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4067/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0721 s/iter. ETA=0:08:31\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4137/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0721 s/iter. ETA=0:08:26\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4207/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0720 s/iter. ETA=0:08:21\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4277/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0720 s/iter. ETA=0:08:16\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4347/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0720 s/iter. ETA=0:08:11\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4417/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0720 s/iter. ETA=0:08:06\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4486/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0720 s/iter. ETA=0:08:01\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4556/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0176 s/iter. Total: 0.0720 s/iter. ETA=0:07:56\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4625/11167. Dataloading: 0.0007 s/iter. Inference: 0.0537 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:51\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4695/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:46\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4765/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:41\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4835/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:36\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4905/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:31\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 4975/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:26\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5045/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:21\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5115/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:16\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5185/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:11\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5255/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:07:06\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5325/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:07:00\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5395/11167. Dataloading: 0.0007 s/iter. Inference: 0.0538 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:06:55\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5465/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:06:50\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5535/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0720 s/iter. ETA=0:06:45\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5605/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0720 s/iter. ETA=0:06:40\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5675/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0720 s/iter. ETA=0:06:35\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5745/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0720 s/iter. ETA=0:06:30\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5796/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0177 s/iter. Total: 0.0723 s/iter. ETA=0:06:28\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5866/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0177 s/iter. Total: 0.0723 s/iter. ETA=0:06:23\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 5936/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0177 s/iter. Total: 0.0723 s/iter. ETA=0:06:18\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6006/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0177 s/iter. Total: 0.0723 s/iter. ETA=0:06:13\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6076/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0723 s/iter. ETA=0:06:08\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6147/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0723 s/iter. ETA=0:06:02\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6217/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0723 s/iter. ETA=0:05:57\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6288/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0723 s/iter. ETA=0:05:52\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6359/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0723 s/iter. ETA=0:05:47\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6429/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0723 s/iter. ETA=0:05:42\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6500/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:37\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6570/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:32\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6640/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:26\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6710/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:21\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6780/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:16\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6850/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:11\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6920/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:06\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 6990/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0176 s/iter. Total: 0.0722 s/iter. ETA=0:05:01\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7060/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:56\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7130/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:51\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7200/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:46\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7270/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:41\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7340/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:36\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7410/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:31\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7480/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:26\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7550/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:21\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7620/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:16\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7690/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:10\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7760/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:05\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7830/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:04:00\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7900/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:03:55\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 7970/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:03:50\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8040/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:03:45\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8110/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0722 s/iter. ETA=0:03:40\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8180/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:03:35\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8250/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:03:30\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8320/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:03:25\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8390/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0175 s/iter. Total: 0.0721 s/iter. ETA=0:03:20\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8459/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:03:15\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8529/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:03:10\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8599/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:03:05\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8669/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:03:00\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8738/11167. Dataloading: 0.0007 s/iter. Inference: 0.0539 s/iter. Eval: 0.0174 s/iter. Total: 0.0721 s/iter. ETA=0:02:55\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8780/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:52\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8849/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:47\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8918/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:42\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 8987/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:37\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9056/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:32\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9125/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:27\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9195/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:22\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9264/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:17\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9333/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:12\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9403/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:07\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9473/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:02:02\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9543/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:57\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9613/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:52\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9682/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:47\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9752/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:42\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9822/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:37\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9891/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:32\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 9961/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:27\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10031/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0176 s/iter. Total: 0.0724 s/iter. ETA=0:01:22\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10101/11167. Dataloading: 0.0007 s/iter. Inference: 0.0540 s/iter. Eval: 0.0175 s/iter. Total: 0.0724 s/iter. ETA=0:01:17\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10171/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0724 s/iter. ETA=0:01:12\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10241/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0724 s/iter. ETA=0:01:07\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10311/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0724 s/iter. ETA=0:01:01\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10381/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0724 s/iter. ETA=0:00:56\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10451/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:51\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10521/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:46\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10591/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:41\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10661/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:36\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10731/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:31\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10801/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:26\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10871/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:21\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 10941/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:16\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 11011/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:11\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 11081/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:06\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 11151/11167. Dataloading: 0.0007 s/iter. Inference: 0.0541 s/iter. Eval: 0.0175 s/iter. Total: 0.0723 s/iter. ETA=0:00:01\n",
      "INFO:detectron2.evaluation.evaluator:Total inference time: 0:13:27.218596 (0.072318 s / iter per device, on 1 devices)\n",
      "INFO:detectron2.evaluation.evaluator:Total inference pure compute time: 0:10:03 (0.054054 s / iter per device, on 1 devices)\n",
      "INFO:detectron2.evaluation.coco_evaluation:Preparing results for COCO format ...\n",
      "INFO:detectron2.evaluation.coco_evaluation:Saving results to eval/coco_instances_results.json\n",
      "INFO:detectron2.evaluation.coco_evaluation:Evaluating predictions with unofficial COCO API...\n",
      "ERROR:detectree2.models.train:Exception during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/detectree2_rooz/detectree2/models/train.py\", line 359, in train\n",
      "    self.after_step()\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/train_loop.py\", line 190, in after_step\n",
      "    h.after_step()\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/hooks.py\", line 556, in after_step\n",
      "    self._do_eval()\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/hooks.py\", line 529, in _do_eval\n",
      "    results = self._func()\n",
      "              ^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/defaults.py\", line 489, in test_and_save_results\n",
      "    self._last_eval_results = self.test(self.cfg, self.model)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/defaults.py\", line 653, in test\n",
      "    results_i = inference_on_dataset(model, data_loader, evaluator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/evaluator.py\", line 213, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pycocotools/coco.py\", line 327, in loadRes\n",
      "    assert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: Results do not correspond to current coco set\n",
      "INFO:detectron2.engine.hooks:Overall training speed: 97 iterations in 0:03:27 (2.1439 s / it)\n",
      "INFO:detectron2.engine.hooks:Total training time: 0:20:38 (0:17:10 on hooks)\n",
      "INFO:detectron2.utils.events: eta: 3:27:07  iter: 99  total_loss: 1.993  loss_cls: 0.2381  loss_box_reg: 0.07219  loss_mask: 0.5124  loss_rpn_cls: 0.4282  loss_rpn_loc: 0.7097    time: 2.1220  last_time: 2.1764  data_time: 0.0281  last_data_time: 0.0181   lr: 3.389e-05  max_mem: 9120M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "No APs were recorded during training. Skipping model selection.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Results do not correspond to current coco set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MyTrainer(cfg, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/detectree2_rooz/detectree2/models/train.py:359\u001b[0m, in \u001b[0;36mMyTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_step()\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stop:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/train_loop.py:190\u001b[0m, in \u001b[0;36mTrainerBase.after_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[0;32m--> 190\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/hooks.py:556\u001b[0m, in \u001b[0;36mEvalHook.after_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_period \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m next_iter \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# do the last eval in after_train\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_iter \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_iter:\n\u001b[0;32m--> 556\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/hooks.py:529\u001b[0m, in \u001b[0;36mEvalHook._do_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 529\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    533\u001b[0m             results, \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m    534\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval function must return a dict. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/defaults.py:489\u001b[0m, in \u001b[0;36mDefaultTrainer.build_hooks.<locals>.test_and_save_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_and_save_results\u001b[39m():\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_eval_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_eval_results\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/engine/defaults.py:653\u001b[0m, in \u001b[0;36mDefaultTrainer.test\u001b[0;34m(cls, cfg, model, evaluators)\u001b[0m\n\u001b[1;32m    651\u001b[0m         results[dataset_name] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m results_i \u001b[38;5;241m=\u001b[39m \u001b[43minference_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m results[dataset_name] \u001b[38;5;241m=\u001b[39m results_i\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/evaluator.py:213\u001b[0m, in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator, callbacks)\u001b[0m\n\u001b[1;32m    206\u001b[0m total_compute_time_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mtimedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(total_compute_time)))\n\u001b[1;32m    207\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal inference pure compute time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m s / iter per device, on \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m devices)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    209\u001b[0m         total_compute_time_str, total_compute_time \u001b[38;5;241m/\u001b[39m (total \u001b[38;5;241m-\u001b[39m num_warmup), num_devices\n\u001b[1;32m    210\u001b[0m     )\n\u001b[1;32m    211\u001b[0m )\n\u001b[0;32m--> 213\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# An evaluator may return None when not in main process.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Replace it by an empty dict instead to make it easier for downstream code to handle\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/coco_evaluation.py:206\u001b[0m, in \u001b[0;36mCOCOEvaluator.evaluate\u001b[0;34m(self, img_ids)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_box_proposals(predictions)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m predictions[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Copy so the caller can do whatever with results\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/coco_evaluation.py:266\u001b[0m, in \u001b[0;36mCOCOEvaluator._eval_predictions\u001b[0;34m(self, predictions, img_ids)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(tasks):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unknown task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m     coco_eval \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 266\u001b[0m         \u001b[43m_evaluate_predictions_on_coco\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coco_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoco_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkpt_oks_sigmas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kpt_oks_sigmas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcocoeval_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOCOeval_opt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_fast_impl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCOCOeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_dets_per_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_dets_per_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(coco_results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# cocoapi does not handle empty results very well\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    279\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_derive_coco_results(\n\u001b[1;32m    280\u001b[0m         coco_eval, task, class_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthing_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results[task] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/detectron2/evaluation/coco_evaluation.py:590\u001b[0m, in \u001b[0;36m_evaluate_predictions_on_coco\u001b[0;34m(coco_gt, coco_results, iou_type, kpt_oks_sigmas, cocoeval_fn, img_ids, max_dets_per_image)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m coco_results:\n\u001b[1;32m    588\u001b[0m         c\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 590\u001b[0m coco_dt \u001b[38;5;241m=\u001b[39m \u001b[43mcoco_gt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadRes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoco_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m coco_eval \u001b[38;5;241m=\u001b[39m cocoeval_fn(coco_gt, coco_dt, iou_type)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# For COCO, the default max_dets_per_image is [1, 10, 100].\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pycocotools/coco.py:327\u001b[0m, in \u001b[0;36mCOCO.loadRes\u001b[0;34m(self, resFile)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(anns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults in not an array of objects\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    326\u001b[0m annsImgIds \u001b[38;5;241m=\u001b[39m [ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns]\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(annsImgIds) \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mset\u001b[39m(annsImgIds) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetImgIds())), \\\n\u001b[1;32m    328\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults do not correspond to current coco set\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m anns[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    330\u001b[0m     imgIds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m]]) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m([ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns])\n",
      "\u001b[0;31mAssertionError\u001b[0m: Results do not correspond to current coco set"
     ]
    }
   ],
   "source": [
    "trainer = MyTrainer(cfg, patience = 30)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
